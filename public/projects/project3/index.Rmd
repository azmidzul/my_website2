---
title: "Project 3: Climate Change and Temperature Anomalies"
author: 
date: "`r Sys.Date()`"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
---


```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, include=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
```



# Climate change and temperature anomalies 


If we wanted to study climate change, we can find data on the *Combined Land-Surface Air and Sea-Surface Water Temperature Anomalies* in the Northern Hemisphere at [NASA's Goddard Institute for Space Studies](https://data.giss.nasa.gov/gistemp). The [tabular data of temperature anomalies can be found here](https://data.giss.nasa.gov/gistemp/tabledata_v3/NH.Ts+dSST.txt)

To define temperature anomalies you need to have a reference, or base, period which NASA clearly states that it is the period between 1951-1980.


```{r weather_data, cache=TRUE}

weather <- 
  read_csv("https://data.giss.nasa.gov/gistemp/tabledata_v3/NH.Ts+dSST.csv", 
           skip = 1, 
           na = "***")

```



```{r tidyweather}

tidyweather <- weather %>%
  select(Year:Dec) %>% 
  pivot_longer(cols=c('Jan':'Dec'),names_to="Month",values_to="delta")


```

## Plotting Information

Let us plot the data using a time-series scatter plot, and add a trendline. To do that, we first need to create a new variable called `date` in order to ensure that the `delta` values are plot chronologically. 


```{r scatter_plot,  }

tidyweather <- tidyweather %>%
  mutate(date = ymd(paste(as.character(Year), Month, "1")),
         month = month(date, label=TRUE),
         year = year(date))

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color="red") +
  theme_wsj() +
  labs (
    title = "Weather Anomalies"
  )

```

Is the effect of increasing temperature more pronounced in some months?

```{r facet_wrap, echo=FALSE}

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  
  geom_smooth(color="red") +
  theme_wsj() +
  labs (
    title = "Weather Anomalies"
  )+
  facet_wrap(~month)

```

It is sometimes useful to group data into different time periods to study historical data. For example, we often refer to decades such as 1970s, 1980s, 1990s etc. to refer to a period of time. NASA calcuialtes a temperature anomaly, as difference form the base periof of 1951-1980. The code below creates a new data frame called `comparison` that groups data in five time periods: 1881-1920, 1921-1950, 1951-1980, 1981-2010 and 2011-present.


```{r intervals,  }

comparison <- tidyweather %>% 
  filter(Year>= 1881) %>%     #remove years prior to 1881
  #create new variable 'interval', and assign values based on criteria below:
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ "1881-1920",
    Year %in% c(1921:1950) ~ "1921-1950",
    Year %in% c(1951:1980) ~ "1951-1980",
    Year %in% c(1981:2010) ~ "1981-2010",
    TRUE ~ "2011-present"
  ))

```


```{r density_plot,  }

ggplot(comparison, aes(x=delta, fill=interval))+
  geom_density(alpha=0.2) +   #density plot with tranparency set to 20%
  theme_wsj() +                #theme
  labs (
    title = "Density Plot for Monthly Temperature Anomalies",
    y     = "Density"         #changing y-axis label to sentence case
  )

```

```{r averaging,  }

#creating yearly averages
average_annual_anomaly <- tidyweather %>% 
  group_by(Year) %>%   #grouping data by Year
  
  # creating summaries for mean delta 
  # use `na.rm=TRUE` to eliminate NA (not available) values 
  summarise(annual_average_delta = mean(delta, na.rm=TRUE)) 

#plotting the data:
ggplot(average_annual_anomaly, aes(x=Year, y= annual_average_delta))+
  geom_point() +
  
  #Fit the best fit line, using LOESS method
  geom_smooth() +
  
  #change to theme_bw() to have white background + black frame around plot
  theme_wsj() +
  labs (
    title = "Average Yearly Anomaly",
    y     = "Average Annual Delta"
  )                         


```


## Confidence Interval for `delta`

[NASA points out on their website](https://earthobservatory.nasa.gov/world-of-change/decadaltemp.php) that 

> A one-degree global change is significant because it takes a vast amount of heat to warm all the oceans, atmosphere, and land by that much. In the past, a one- to two-degree drop was all it took to plunge the Earth into the Little Ice Age.


```{r, calculate_CI_using_formula,  }

formula_ci <- comparison %>% 
  filter(interval=="2011-present",!is.na(delta)) %>% 
  summarize(
    Average=mean(delta),
    Std_Dev=sd(delta),
    count=n(),
    Std_Err=Std_Dev/(sqrt(count)),
    Critical_Value=qt(0.95,count-1),
    Margin_Error=Std_Err*Critical_Value,
    Conf_Interval_Lower=Average-Margin_Error,
    Conf_Interval_Upper=Average+Margin_Error)
  # calculate lower/upper 95% CI
  

  # calculate summary statistics for temperature deviation (delta) 
  # calculate mean, SD, count, SE, lower/upper 95% CI
  # what dplyr verb will you use? 

#print out formula_CI
formula_ci
```


```{r, calculate_CI_using_bootstrap}
library(infer)
set.seed(1234)
boot.temperature<-comparison %>% 
  filter(interval=="2011-present",!is.na(delta)) %>% 
  specify(response=delta) %>% 
  generate(reps=1000,type="bootstrap") %>%
  calculate(stat="mean")

CI<-boot.temperature %>% 
  get_confidence_interval(level=0.95,type="percentile")

CI
# use the infer package to construct a 95% CI for delta

```

*First, we set the seed so R samples the same sample each time, so that our results will be the same when we (or someone else) reproduces them. Then, we filtered the data for the timeframe we wanted (2011-present), and cleared out any rows with empty delta values. We generated 1000 resamples of delta values with 103 observations in each, all in this specified time period with the sampling method boostrapping: sampling with replacement, meaning that if our sample space were a hat, whatever you take out of the hat, you have to put back into it before taking another sample out. Then we calculated the mean for 1000 samples, and from these sample means, we calculated the 95% confidence interval (displayed above) which means that there is a 95% chance that this confidence interval contains the true population mean.* 


